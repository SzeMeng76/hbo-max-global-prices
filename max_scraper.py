#!/usr/bin/env python3
"""
HBO Max Global Price Scraper
è‡ªåŠ¨æŠ“å–å…¨çƒ HBO Max è®¢é˜…ä»·æ ¼ï¼Œæ”¯æŒä»£ç†å’Œå¹¶å‘å¤„ç†
åŸºäºåŸæœ‰ max.py ä»£ç ï¼Œä¼˜åŒ–ä¸ºæ‰¹é‡è‡ªåŠ¨åŒ–å¤„ç†
"""

import asyncio
import json
import os
import time
import random
import traceback
import re
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime
import httpx
from bs4 import BeautifulSoup

# ç¡®ä¿ BS4 å¯ç”¨
try:
    from bs4 import BeautifulSoup
    BS4_INSTALLED = True
except ImportError:
    BS4_INSTALLED = False
    print("âŒ è¯·å®‰è£… BeautifulSoup4: pip install beautifulsoup4")
    exit(1)

# --- å¸¸é‡å®šä¹‰ ---
MAX_URL = "https://www.max.com"

# é™æ€åŒºåŸŸæ˜ å°„ï¼šå›½å®¶ä»£ç  -> å¤šè¯­è¨€ URL è·¯å¾„åˆ—è¡¨ï¼ˆåŸºäºåŸæœ‰max.pyï¼‰
REGION_PATHS: Dict[str, List[str]] = {
    "my": ["/my/en", "/my/zh", "/my/ms"],
    "hk": ["/hk/en", "/hk/zh"],
    "ph": ["/ph/en", "/ph/tl"],
    "tw": ["/tw/en", "/tw/zh"],
    "id": ["/id/en", "/id/id"],
    "sg": ["/sg/en", "/sg/ms"],
    "th": ["/th/en", "/th/th"],
    "co": ["/co/es"], "cr": ["/cr/es"], "gt": ["/gt/es"], "pe": ["/pe/es"],
    "uy": ["/uy/es"], "mx": ["/mx/es"], "hn": ["/hn/es"], "ni": ["/ni/es"],
    "pa": ["/pa/es"], "ar": ["/ar/es"], "bo": ["/bo/es"], "do": ["/do/es"],
    "ec": ["/ec/es"], "sv": ["/sv/es"], "py": ["/py/es"], "cl": ["/cl/es"],
    "br": ["/br/pt"],
    "jm": ["/jm/en"], "ms": ["/ms/en"], "ai": ["/ai/en"], "ag": ["/ag/en"],
    "aw": ["/aw/en"], "bs": ["/bs/en"], "bb": ["/bb/en"], "bz": ["/bz/en"],
    "vg": ["/vg/en"], "ky": ["/ky/en"], "cw": ["/cw/en"], "dm": ["/dm/en"],
    "gd": ["/gd/en"], "gy": ["/gy/en"], "ht": ["/ht/en"], "kn": ["/kn/en"],
    "lc": ["/lc/en"], "vc": ["/vc/en"], "sr": ["/sr/en"], "tt": ["/tt/en"],
    "tc": ["/tc/en"],
    "us": ["/us/en", "/us/es"],
    "au": ["/au/en"],
    "ad": ["/ad/en", "/ad/es"],
    "ba": ["/ba/en", "/ba/hr"],
    "bg": ["/bg/en", "/bg/bg"],
    "hr": ["/hr/en", "/hr/hr"],
    "cz": ["/cz/en", "/cz/cs"],
    "hu": ["/hu/en", "/hu/hu"],
    "mk": ["/mk/en", "/mk/mk"],
    "md": ["/md/en", "/md/ro"],
    "me": ["/me/en", "/me/sr"],
    "ro": ["/ro/en", "/ro/ro"],
    "rs": ["/rs/en", "/rs/sr"],
    "sk": ["/sk/en", "/sk/sk"],
    "si": ["/si/en", "/si/sl"],
    "dk": ["/dk/en", "/dk/da"],
    "fi": ["/fi/en", "/fi/fi"],
    "no": ["/no/en", "/no/no"],
    "se": ["/se/en", "/se/sv"],
    "es": ["/es/en", "/es/es"],
    "fr": ["/fr/en", "/fr/fr"],
    "be": ["/be/en", "/be/nl", "/be/fr"],
    "pt": ["/pt/en", "/pt/pt"],
    "nl": ["/nl/en", "/nl/nl"],
    "pl": ["/pl/pl"],
    "tr": ["/tr/en", "/tr/tr"],
}

# å›½å®¶åç§°æ˜ å°„
COUNTRY_NAMES = {
    "my": "Malaysia", "hk": "Hong Kong", "ph": "Philippines", "tw": "Taiwan",
    "id": "Indonesia", "sg": "Singapore", "th": "Thailand", "co": "Colombia",
    "cr": "Costa Rica", "gt": "Guatemala", "pe": "Peru", "uy": "Uruguay",
    "mx": "Mexico", "hn": "Honduras", "ni": "Nicaragua", "pa": "Panama",
    "ar": "Argentina", "bo": "Bolivia", "do": "Dominican Republic", "ec": "Ecuador",
    "sv": "El Salvador", "py": "Paraguay", "cl": "Chile", "br": "Brazil",
    "jm": "Jamaica", "ms": "Montserrat", "ai": "Anguilla", "ag": "Antigua and Barbuda",
    "aw": "Aruba", "bs": "Bahamas", "bb": "Barbados", "bz": "Belize",
    "vg": "British Virgin Islands", "ky": "Cayman Islands", "cw": "Curacao",
    "dm": "Dominica", "gd": "Grenada", "gy": "Guyana", "ht": "Haiti",
    "kn": "Saint Kitts and Nevis", "lc": "Saint Lucia", "vc": "Saint Vincent and the Grenadines",
    "sr": "Suriname", "tt": "Trinidad and Tobago", "tc": "Turks and Caicos Islands",
    "us": "United States", "au": "Australia", "ad": "Andorra", "ba": "Bosnia and Herzegovina",
    "bg": "Bulgaria", "hr": "Croatia", "cz": "Czech Republic", "hu": "Hungary",
    "mk": "North Macedonia", "md": "Moldova", "me": "Montenegro", "ro": "Romania",
    "rs": "Serbia", "sk": "Slovakia", "si": "Slovenia", "dk": "Denmark",
    "fi": "Finland", "no": "Norway", "se": "Sweden", "es": "Spain",
    "fr": "France", "be": "Belgium", "pt": "Portugal", "nl": "Netherlands",
    "pl": "Poland", "tr": "Turkey"
}

# è¯·æ±‚å¤´é…ç½®
USER_AGENTS: List[str] = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 Chrome/120.0 Safari/537.36",  
    "Mozilla/5.0 (Windows NT 10.0; rv:120.0) Gecko/20100101 Firefox/120.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; x64) AppleWebKit/537.36 Edg/120.0"
]

BASE_HEADERS: Dict[str, str] = {
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.9",
    "Upgrade-Insecure-Requests": "1",
    "DNT": "1",
    "Sec-GPC": "1"
}

# ä»£ç†APIé…ç½®ï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
PROXY_API_TEMPLATE = os.getenv("PROXY_API_TEMPLATE", "http://api.mooproxy.xyz/v1/gen?user=Domo_lee&country={country}&pass=UNuYSniZ8D")

def extract_year_from_timestamp(timestamp: str) -> str:
    """ä»æ—¶é—´æˆ³ä¸­æå–å¹´ä»½"""
    try:
        if len(timestamp) >= 4:
            return timestamp[:4]
        else:
            return time.strftime('%Y')
    except:
        return time.strftime('%Y')

def create_archive_directory_structure(archive_dir: str, timestamp: str) -> str:
    """æ ¹æ®æ—¶é—´æˆ³åˆ›å»ºæŒ‰å¹´ä»½ç»„ç»‡çš„å½’æ¡£ç›®å½•ç»“æ„"""
    year = extract_year_from_timestamp(timestamp)
    year_dir = os.path.join(archive_dir, year)
    if not os.path.exists(year_dir):
        os.makedirs(year_dir)
        print(f"ğŸ“ åˆ›å»ºå¹´ä»½ç›®å½•: {year_dir}")
    return year_dir

async def get_proxy(country_code: str) -> Optional[Dict[str, str]]:
    """è·å–æŒ‡å®šå›½å®¶çš„ä»£ç†"""
    url = PROXY_API_TEMPLATE.format(country=country_code.lower())
    try:
        async with httpx.AsyncClient(timeout=25.0) as client:
            print(f"ğŸ”„ {country_code}: è·å–ä»£ç†...")
            resp = await client.get(url)
            resp.raise_for_status()
            data = resp.json()
            plist = data.get("proxies") or []
            if not plist:
                raise ValueError("ä»£ç†åˆ—è¡¨ä¸ºç©º")
            
            host, port, user, *rest = plist[0].split(":")
            password = ":".join(rest)
            if not port.isdigit():
                raise ValueError("ç«¯å£å·æ— æ•ˆ")
                
            full = f"http://{user}:{password}@{host}:{port}"
            print(f"âœ… {country_code}: ä»£ç†è·å–æˆåŠŸ {host}:{port}")
            return {"http://": full, "https://": full}
    except Exception as e:
        print(f"âŒ {country_code}: ä»£ç†è·å–å¤±è´¥ - {e}")
        return None

async def fetch_max_page(country_code: str, proxies: Dict[str, str], headers: Dict[str, str]) -> Optional[str]:
    """è·å–HBO Maxé¡µé¢å†…å®¹"""
    cc = country_code.lower()
    paths = REGION_PATHS.get(cc)
    
    # ä¼˜å…ˆä½¿ç”¨é™æ€æ˜ å°„
    if paths:
        for path in paths:
            url = MAX_URL + path
            try:
                async with httpx.AsyncClient(proxies=proxies, headers=headers, follow_redirects=True, timeout=45.0) as client:
                    print(f"ğŸŒ {country_code}: è®¿é—® {url}")
                    r = await client.get(url)
                    print(f"ğŸ“Š {country_code}: å“åº” {r.status_code} -> {r.url}")
                    r.raise_for_status()
                    return r.text
            except httpx.HTTPStatusError as e:
                print(f"âš ï¸ {country_code}: HTTP {e.response.status_code} - å°è¯•ä¸‹ä¸€ä¸ªè·¯å¾„")
                continue
            except Exception as e:
                print(f"âŒ {country_code}: è®¿é—®å¤±è´¥ - {e}")
                continue
        return None
    
    # æ— æ˜ å°„æ—¶çš„é€šç”¨é€»è¾‘
    default_url = f"{MAX_URL}/{cc}/"
    try:
        async with httpx.AsyncClient(proxies=proxies, headers=headers, follow_redirects=True, timeout=45.0) as client:
            print(f"ğŸŒ {country_code}: è®¿é—® {default_url}")
            r = await client.get(default_url)
            print(f"ğŸ“Š {country_code}: å“åº” {r.status_code} -> {r.url}")
            r.raise_for_status()
            return r.text
    except httpx.HTTPStatusError as e:
        # 404æ—¶å›é€€åˆ°è¥¿ç­ç‰™è¯­
        if e.response.status_code == 404:
            fallback = f"{MAX_URL}/{cc}/es"
            try:
                async with httpx.AsyncClient(proxies=proxies, headers=headers, follow_redirects=True, timeout=30.0) as client:
                    print(f"ğŸ”„ {country_code}: è¥¿è¯­å›é€€ {fallback}")
                    r2 = await client.get(fallback)
                    print(f"ğŸ“Š {country_code}: å›é€€å“åº” {r2.status_code} -> {r2.url}")
                    r2.raise_for_status()
                    return r2.text
            except Exception:
                pass
        return None
    except Exception as e:
        print(f"âŒ {country_code}: è®¿é—®å‡ºé”™ - {e}")
        return None

def extract_price_number(price_str: str) -> float:
    """ä»ä»·æ ¼å­—ç¬¦ä¸²ä¸­æå–æ•°å€¼ï¼ˆå‚è€ƒSpotifyé¡¹ç›®çš„é€»è¾‘ï¼‰"""
    if not price_str:
        return 0.0
    
    # æŸ¥æ‰¾æ•°å­—ã€é€—å·ã€ç‚¹çš„è¿ç»­ç»„åˆ
    number_pattern = r'([\d,\.]+)'
    number_matches = re.findall(number_pattern, price_str)
    
    if not number_matches:
        return 0.0
    
    # æ‰¾åˆ°æœ€é•¿çš„æ•°å­—ä¸²ï¼ˆé€šå¸¸æ˜¯ä»·æ ¼ï¼‰
    number_part = max(number_matches, key=len)
    
    # å¦‚æœæ²¡æœ‰æ•°å­—ï¼Œè¿”å›0
    if not re.search(r'\d', number_part):
        return 0.0 
    
    # å¤„ç†ä¸åŒçš„æ•°å­—æ ¼å¼
    cleaned = number_part
    if ',' in cleaned and '.' in cleaned:
        # åˆ¤æ–­æ˜¯æ¬§å¼æ ¼å¼è¿˜æ˜¯ç¾å¼æ ¼å¼
        comma_pos = cleaned.rindex(',')
        dot_pos = cleaned.rindex('.')
        if comma_pos > dot_pos:
            # æ¬§å¼æ ¼å¼ (1.234,56) - ç‚¹æ˜¯åƒä½åˆ†éš”ç¬¦ï¼Œé€—å·æ˜¯å°æ•°ç‚¹
            cleaned = cleaned.replace('.', '').replace(',', '.')
        else:
            # ç¾å¼æ ¼å¼ (1,234.56) - é€—å·æ˜¯åƒä½åˆ†éš”ç¬¦ï¼Œç‚¹æ˜¯å°æ•°ç‚¹
            cleaned = cleaned.replace(',', '')
    elif ',' in cleaned:
        # åªæœ‰é€—å·çš„æƒ…å†µ
        parts = cleaned.split(',')
        if len(parts) == 2:
            # æ£€æŸ¥å°æ•°éƒ¨åˆ†é•¿åº¦æ¥åˆ¤æ–­æ˜¯å°æ•°ç‚¹è¿˜æ˜¯åƒä½åˆ†éš”ç¬¦
            decimal_part = parts[-1]
            if len(decimal_part) <= 2:
                # å°æ•°éƒ¨åˆ†æ˜¯1-2ä½æ•°ï¼Œå¾ˆå¯èƒ½æ˜¯å°æ•°ç‚¹ (ä¾‹å¦‚: 5,99)
                cleaned = cleaned.replace(',', '.')
            else:
                # å°æ•°éƒ¨åˆ†è¶…è¿‡2ä½ï¼Œå¾ˆå¯èƒ½æ˜¯åƒä½åˆ†éš”ç¬¦ (ä¾‹å¦‚: 2,499)
                cleaned = cleaned.replace(',', '')
        else:
            # å¤šä¸ªé€—å·ï¼Œéƒ½æ˜¯åƒä½åˆ†éš”ç¬¦
            cleaned = cleaned.replace(',', '')
    elif '.' in cleaned:
        # åªæœ‰ç‚¹çš„æƒ…å†µ
        parts = cleaned.split('.')
        if len(parts) == 2:
            # æ£€æŸ¥å°æ•°éƒ¨åˆ†é•¿åº¦
            decimal_part = parts[-1]
            if len(decimal_part) <= 2:
                # å°æ•°éƒ¨åˆ†æ˜¯1-2ä½æ•°ï¼Œä¿æŒä¸ºå°æ•°ç‚¹ (ä¾‹å¦‚: 5.99)
                pass  # ä¿æŒä¸å˜
            else:
                # å°æ•°éƒ¨åˆ†è¶…è¿‡2ä½ï¼Œå¾ˆå¯èƒ½æ˜¯åƒä½åˆ†éš”ç¬¦ (ä¾‹å¦‚: 2.499)
                cleaned = cleaned.replace('.', '')
        else:
            # å¤šä¸ªç‚¹ï¼Œéƒ½æ˜¯åƒä½åˆ†éš”ç¬¦
            cleaned = cleaned.replace('.', '')
    
    try:
        return float(cleaned)
    except ValueError:
        return 0.0

def detect_currency(price_str: str) -> str:
    """æ£€æµ‹ä»·æ ¼å­—ç¬¦ä¸²ä¸­çš„è´§å¸"""
    currency_symbols = {
        'US$': 'USD', 'USD': 'USD', '$': 'USD',
        'C$': 'CAD', 'CA$': 'CAD', 'A$': 'AUD', 'S$': 'SGD', 'HK$': 'HKD',
        'MX$': 'MXN', 'NZ$': 'NZD', 'NT$': 'TWD', 'R$': 'BRL',
        'â‚¬': 'EUR', 'EUR': 'EUR', 'Â£': 'GBP', 'GBP': 'GBP',
        'Â¥': 'JPY', 'ï¿¥': 'JPY', 'JPY': 'JPY',
        'â‚¹': 'INR', 'INR': 'INR', 'â‚±': 'PHP', 'PHP': 'PHP',
        'â‚ª': 'ILS', 'â‚¨': 'PKR', 'â‚¦': 'NGN', 'â‚µ': 'GHS',
        'â‚¡': 'CRC', 'â‚©': 'KRW', 'â‚´': 'UAH', 'â‚½': 'RUB',
        'â‚º': 'TRY', 'TRY': 'TRY', 'zÅ‚': 'PLN', 'PLN': 'PLN',
        'KÄ': 'CZK', 'CZK': 'CZK', 'Ft': 'HUF', 'HUF': 'HUF',
        'CHF': 'CHF', 'NOK': 'NOK', 'SEK': 'SEK', 'DKK': 'DKK',
        'kr': 'SEK'
    }
    
    # æŒ‰ç¬¦å·é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼Œä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„ç¬¦å·
    sorted_symbols = sorted(currency_symbols.items(), key=lambda x: len(x[0]), reverse=True)
    
    for symbol, currency in sorted_symbols:
        if symbol in price_str:
            return currency
    
    # é»˜è®¤è¿”å›ç¾å…ƒ
    return 'USD'

async def parse_max_prices(html: str, country_code: str) -> Tuple[List[Dict[str, Any]], str]:
    """è§£æHBO Maxé¡µé¢ä»·æ ¼ä¿¡æ¯ï¼Œè¿”å›ï¼ˆç»“æ„åŒ–æ•°æ®åˆ—è¡¨, æ–‡æœ¬è¾“å‡ºï¼‰"""
    if not html:
        err = f"âŒ æ— æ³•è·å–é¡µé¢å†…å®¹ ({country_code})"
        return [], err
    
    try:
        soup = BeautifulSoup(html, 'html.parser')
        sections = soup.find_all('section', {'data-plan-group': True})
        plans: List[Dict[str, Any]] = []
        seen: set = set()
        
        if sections:
            print(f"ğŸ“Š {country_code}: æ‰¾åˆ° {len(sections)} ä¸ªä»·æ ¼åŒºåŸŸ")
            for sec in sections:
                p = sec['data-plan-group']
                label = 'æ¯æœˆ' if p == 'monthly' else 'æ¯å¹´'
                cards = sec.find_all('div', class_='max-plan-picker-group__card')
                print(f"ğŸ“¦ {country_code}: {label} åŒºåŸŸæ‰¾åˆ° {len(cards)} ä¸ªå¥—é¤")
                
                for card in cards:
                    try:
                        name_elem = card.find('h3')
                        price_elem = card.find('h4')
                        
                        if not name_elem or not price_elem:
                            continue
                            
                        name = name_elem.get_text(strip=True)
                        price = price_elem.get_text(strip=True)
                        
                        key = (p, name, price)
                        if key in seen:
                            continue
                        seen.add(key)
                        
                        # æå–ä»·æ ¼æ•°å€¼å’Œè´§å¸
                        price_number = extract_price_number(price)
                        currency = detect_currency(price)
                        
                        plan_data = {
                            "plan_group": p,
                            "label": label,
                            "name": name,
                            "price": price,
                            "price_number": price_number,
                            "currency": currency
                        }
                        plans.append(plan_data)
                        print(f"âœ… {country_code}: {name} ({label}) - {price} ({currency})")
                        
                    except Exception as e:
                        print(f"âš ï¸ {country_code}: è§£æå¥—é¤å¤±è´¥ - {e}")
                        continue
            
            # æ„å»ºè¾“å‡ºæ–‡æœ¬
            if plans:
                out = [f"**HBO Max {country_code.upper()} è®¢é˜…ä»·æ ¼:**"]
                for item in plans:
                    out.append(f"âœ… {item['name']} ({item['label']}): **{item['price']}**")
                return plans, "\n".join(out)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†ç»“æ„ï¼Œå°è¯•å…¶ä»–è§£ææ–¹æ³•
        print(f"ğŸ” {country_code}: æœªæ‰¾åˆ°æ ‡å‡†ä»·æ ¼ç»“æ„ï¼Œå°è¯•å¤‡ç”¨è§£æ...")
        
        # æŸ¥æ‰¾ä»·æ ¼ç›¸å…³çš„å…ƒç´ 
        price_elements = soup.find_all(['div', 'span', 'p'], class_=re.compile(r'price|cost|plan', re.I))
        if price_elements:
            print(f"ğŸ“Š {country_code}: æ‰¾åˆ° {len(price_elements)} ä¸ªä»·æ ¼ç›¸å…³å…ƒç´ ")
            for elem in price_elements[:5]:  # åªå–å‰5ä¸ªé¿å…è¿‡å¤š
                text = elem.get_text(strip=True)
                if re.search(r'[â‚¬$Â£Â¥â‚¹â‚±â‚ªâ‚¨â‚¦â‚µâ‚¡]\s*[\d,.]|\d+[\d,.]*\s*[â‚¬$Â£Â¥â‚¹â‚±â‚ªâ‚¨â‚¦â‚µâ‚¡]', text):
                    price_number = extract_price_number(text)
                    currency = detect_currency(text)
                    if price_number > 0:
                        plans.append({
                            "plan_group": "unknown",
                            "label": "æœªçŸ¥å‘¨æœŸ",
                            "name": "HBO Max Plan",
                            "price": text,
                            "price_number": price_number,
                            "currency": currency
                        })
                        print(f"âœ… {country_code}: å¤‡ç”¨è§£æ - {text} ({currency})")
                        break
        
        if plans:
            out = [f"**HBO Max {country_code.upper()} è®¢é˜…ä»·æ ¼:**"]
            for item in plans:
                out.append(f"âœ… {item['name']} ({item['label']}): **{item['price']}**")
            return plans, "\n".join(out)
        
    except Exception as e:
        print(f"âŒ {country_code}: è§£æå¤±è´¥ - {e}")
        err = f"âŒ è§£æå‡ºé”™: {e}"
        return [], err
    
    return [], f"âŒ {country_code}: æœªè§£æåˆ°ä»»ä½•ä»·æ ¼"

async def get_max_prices_for_country(country_code: str, max_retries: int = 2, semaphore: asyncio.Semaphore = None) -> Optional[Dict[str, Any]]:
    """è·å–æŒ‡å®šå›½å®¶çš„HBO Maxä»·æ ¼"""
    if semaphore:
        async with semaphore:
            return await _get_max_prices_for_country_impl(country_code, max_retries)
    else:
        return await _get_max_prices_for_country_impl(country_code, max_retries)

async def _get_max_prices_for_country_impl(country_code: str, max_retries: int) -> Optional[Dict[str, Any]]:
    """è·å–æŒ‡å®šå›½å®¶çš„HBO Maxä»·æ ¼çš„å†…éƒ¨å®ç°"""
    country_name = COUNTRY_NAMES.get(country_code.lower(), country_code.upper())
    
    for attempt in range(max_retries):
        try:
            print(f"\nğŸŒ {country_code} ({country_name}) - å°è¯• {attempt + 1}/{max_retries}")
            
            # è·å–ä»£ç†
            proxies = await get_proxy(country_code)
            if not proxies:
                print(f"âŒ {country_code}: æ— æ³•è·å–ä»£ç†ï¼Œå°è¯•ä¸‹ä¸€æ¬¡")
                if attempt < max_retries - 1:
                    await asyncio.sleep(random.uniform(2, 5))
                    continue
                else:
                    return None
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {**BASE_HEADERS, 'User-Agent': random.choice(USER_AGENTS)}
            
            # è·å–é¡µé¢å†…å®¹
            html = await fetch_max_page(country_code, proxies, headers)
            if not html:
                print(f"âŒ {country_code}: æ— æ³•è·å–é¡µé¢å†…å®¹")
                if attempt < max_retries - 1:
                    await asyncio.sleep(random.uniform(2, 5))
                    continue
                else:
                    return None
            
            # è§£æä»·æ ¼
            plans, result_text = await parse_max_prices(html, country_code)
            
            if plans:
                print(f"ğŸ¯ {country_code}: æˆåŠŸè·å– {len(plans)} ä¸ªå¥—é¤")
                return {
                    'country_code': country_code.upper(),
                    'country_name': country_name,
                    'plans': plans,
                    'scraped_at': datetime.now().isoformat(),
                    'attempt': attempt + 1,
                    'success': True
                }
            else:
                print(f"âš ï¸ {country_code}: æœªè·å–åˆ°ä»·æ ¼ä¿¡æ¯")
                if attempt < max_retries - 1:
                    await asyncio.sleep(random.uniform(2, 5))
                    continue
                else:
                    return None
                    
        except Exception as e:
            print(f"âŒ {country_code}: å¤„ç†å¤±è´¥ - {e}")
            if attempt < max_retries - 1:
                await asyncio.sleep(random.uniform(2, 5))
                continue
            else:
                return None
    
    return None

async def main():
    """ä¸»å‡½æ•°ï¼šå¹¶å‘è·å–å„å›½HBO Maxä»·æ ¼"""
    print("ğŸ¬ HBO Max Global Price Scraper å¯åŠ¨...")
    print("ğŸš€ ä½¿ç”¨å¹¶å‘æ¨¡å¼ï¼ŒåŒæ—¶å¤„ç†å¤šä¸ªå›½å®¶")
    
    results = {}
    failed_countries = []
    
    # è·å–æ‰€æœ‰å›½å®¶ä»£ç 
    all_countries = list(REGION_PATHS.keys())
    total_countries = len(all_countries)
    max_concurrent = 5  # æœ€å¤§å¹¶å‘æ•°ï¼Œé¿å…è¿‡å¤šè¯·æ±‚
    
    print(f"ğŸ“Š å‡†å¤‡å¤„ç† {total_countries} ä¸ªå›½å®¶/åœ°åŒº")
    
    # åˆ›å»ºä¿¡å·é‡æ¥é™åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_country_with_semaphore(country_code: str, index: int):
        """ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘çš„å›½å®¶å¤„ç†å‡½æ•°"""
        print(f"\nğŸ”„ å¼€å§‹å¤„ç†: {index+1}/{total_countries} - {country_code}")
        
        # è·å–è¯¥å›½å®¶çš„ä»·æ ¼
        country_data = await get_max_prices_for_country(country_code, semaphore=semaphore)
        
        if country_data:
            results[country_code.upper()] = country_data
            print(f"âœ… {country_code}: æˆåŠŸè·å– {len(country_data['plans'])} ä¸ªå¥—é¤")
            return True, country_code
        else:
            failed_countries.append(f"{country_code} ({COUNTRY_NAMES.get(country_code.lower(), country_code)})")
            print(f"âŒ {country_code}: è·å–å¤±è´¥")
            return False, country_code
    
    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
    tasks = []
    for i, country_code in enumerate(all_countries):
        task = process_country_with_semaphore(country_code, i)
        tasks.append(task)
    
    # åˆ†æ‰¹å¤„ç†ä»¥é¿å…è¿‡è½½
    batch_size = 15  # æ¯æ‰¹å¤„ç†15ä¸ªå›½å®¶
    
    print(f"ğŸš€ å¼€å§‹å¹¶å‘å¤„ç†ï¼ˆæœ€å¤§å¹¶å‘æ•°: {max_concurrent}ï¼Œæ‰¹å¤„ç†å¤§å°: {batch_size}ï¼‰...")
    
    for i in range(0, len(tasks), batch_size):
        batch = tasks[i:i+batch_size]
        batch_start = i + 1
        batch_end = min(i + batch_size, len(tasks))
        
        print(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_start}-{batch_end}/{total_countries}")
        
        # å¹¶å‘æ‰§è¡Œå½“å‰æ‰¹æ¬¡
        batch_results = await asyncio.gather(*batch, return_exceptions=True)
        
        # å¤„ç†æ‰¹æ¬¡ç»“æœ
        for result in batch_results:
            if isinstance(result, Exception):
                print(f"âŒ æ‰¹æ¬¡ä¸­å‘ç”Ÿå¼‚å¸¸: {result}")
            elif isinstance(result, tuple) and len(result) == 2:
                success, country_code = result
                if success:
                    print(f"ğŸ“Š æ‰¹æ¬¡å®Œæˆ: {country_code} âœ…")
                else:
                    print(f"ğŸ“Š æ‰¹æ¬¡å®Œæˆ: {country_code} âŒ")
        
        # æ‰¹æ¬¡é—´æ·»åŠ å»¶è¿Ÿ
        if i + batch_size < len(tasks):
            delay = random.uniform(3, 8)
            print(f"â±ï¸  æ‰¹æ¬¡é—´ç­‰å¾… {delay:.1f} ç§’...")
            await asyncio.sleep(delay)
    
    # ä¿å­˜ç»“æœ
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    output_file = f'max_prices_all_countries_{timestamp}.json'
    output_file_latest = 'max_prices_all_countries.json'
    
    # ç¡®ä¿å½’æ¡£ç›®å½•ç»“æ„å­˜åœ¨
    archive_dir = 'archive'
    if not os.path.exists(archive_dir):
        os.makedirs(archive_dir)
    
    # æ ¹æ®æ—¶é—´æˆ³åˆ›å»ºå¹´ä»½å­ç›®å½•
    year_archive_dir = create_archive_directory_structure(archive_dir, timestamp)
    
    # ä¿å­˜å¸¦æ—¶é—´æˆ³çš„ç‰ˆæœ¬åˆ°å¯¹åº”å¹´ä»½å½’æ¡£ç›®å½•
    archive_file = os.path.join(year_archive_dir, output_file)
    with open(archive_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜æœ€æ–°ç‰ˆæœ¬ï¼ˆä¾›è½¬æ¢å™¨ä½¿ç”¨ï¼‰
    with open(output_file_latest, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\n" + "="*60)
    print(f"ğŸ‰ HBO Max ä»·æ ¼æŠ“å–å®Œæˆï¼")
    print(f"âœ… æˆåŠŸ: {len(results)} ä¸ªå›½å®¶")
    print(f"âŒ å¤±è´¥: {len(failed_countries)} ä¸ªå›½å®¶")
    print(f"ğŸ“ å†å²ç‰ˆæœ¬å·²ä¿å­˜åˆ°: {archive_file}")
    print(f"ğŸ“ æœ€æ–°ç‰ˆæœ¬å·²ä¿å­˜åˆ°: {output_file_latest}")
    
    if failed_countries:
        print(f"\nâŒ å¤±è´¥çš„å›½å®¶: {', '.join(failed_countries)}")
    
    # æ˜¾ç¤ºæˆåŠŸç‡ç»Ÿè®¡
    success_rate = len(results) / total_countries * 100
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»å›½å®¶æ•°: {total_countries}")
    print(f"  æˆåŠŸè·å–: {len(results)} ä¸ªå›½å®¶")
    print(f"  å¤±è´¥æ•°é‡: {len(failed_countries)} ä¸ªå›½å®¶")
    print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
    
    return results

if __name__ == '__main__':
    # è¿è¡Œçˆ¬è™«
    try:
        results = asyncio.run(main())
        
        # æ˜¾ç¤ºä¸€äº›æ ·æœ¬æ•°æ®
        if results:
            print(f"\nğŸ“‹ æ ·æœ¬æ•°æ®:")
            for country_code, data in list(results.items())[:3]:
                print(f"\n{country_code} - {data.get('country_name', 'Unknown')}:")
                for plan in data.get('plans', []):
                    print(f"  ğŸ“¦ {plan.get('name', 'Unknown')}: {plan.get('price', 'N/A')}")
        
        print(f"\nğŸ¬ HBO Max ä»·æ ¼æŠ“å–ä»»åŠ¡å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        print(traceback.format_exc())